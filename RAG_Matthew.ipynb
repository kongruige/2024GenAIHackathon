{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XtLNrURSs_C1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1709398567648,
     "user_tz": 0,
     "elapsed": 20803,
     "user": {
      "displayName": "Matthew Zhang",
      "userId": "02723002670783510319"
     }
    },
    "outputId": "3d0fc00b-3423-462d-8446-bf092030b70a"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Packages Config"
   ],
   "metadata": {
    "id": "8obVPTbFMWO-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "!pip install pyautogen\n",
    "!pip install \"pyautogen[retrievechat]\""
   ],
   "metadata": {
    "id": "YclxYhPdMbQ2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1709398583621,
     "user_tz": 0,
     "elapsed": 15978,
     "user": {
      "displayName": "Matthew Zhang",
      "userId": "02723002670783510319"
     }
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR KEY\"\n",
    "\n",
    "llm_config = {\n",
    "    \"config_list\": [{\"model\": \"gpt-3.5-turbo-0125\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}],\n",
    "    \"temperature\": 0.9,\n",
    "    \"seed\": 42\n",
    "}\n",
    "base_dir = '/content/drive/MyDrive/2024 Cambridge Hackathon'"
   ],
   "metadata": {
    "id": "r3R7vn7VQliM",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1709398583621,
     "user_tz": 0,
     "elapsed": 3,
     "user": {
      "displayName": "Matthew Zhang",
      "userId": "02723002670783510319"
     }
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import autogen\n",
    "from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent"
   ],
   "metadata": {
    "id": "sDy7m1-GD_1j",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1709398583621,
     "user_tz": 0,
     "elapsed": 3,
     "user": {
      "displayName": "Matthew Zhang",
      "userId": "02723002670783510319"
     }
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "llm_config = {\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"retrieve_content\",\n",
    "            \"description\": \"retrieve content for code generation and question answering.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"message\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Refined message which keeps the original meaning and can be used to retrieve content for code generation and question answering.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"message\"],\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "    \"config_list\": [{\"model\": \"gpt-3.5-turbo-0125\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}],\n",
    "    \"timeout\": 60,\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "boss = autogen.UserProxyAgent(\n",
    "    name=\"Boss\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    human_input_mode=\"TERMINATE\",\n",
    "    system_message=\"The boss who ask questions and give tasks.\",\n",
    ")\n",
    "\n",
    "boss_aid = RetrieveUserProxyAgent(\n",
    "    name=\"Boss_Assistant\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    system_message=\"Assistant who has extra content retrieval power for solving difficult problems.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=3,\n",
    "    retrieve_config={\n",
    "        \"task\": \"qa\",\n",
    "    },\n",
    "    code_execution_config=False,  # we don't want to execute code in this case.\n",
    ")\n",
    "\n",
    "coder = AssistantAgent(\n",
    "    name=\"Senior_Python_Engineer\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    system_message=\"You are a senior python engineer. Reply `TERMINATE` in the end when everything is done.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "pm = autogen.AssistantAgent(\n",
    "    name=\"Product_Manager\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    system_message=\"You are a product manager. Reply `TERMINATE` in the end when everything is done.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "reviewer = autogen.AssistantAgent(\n",
    "    name=\"Code_Reviewer\",\n",
    "    is_termination_msg=termination_msg,\n",
    "    system_message=\"You are a code reviewer. Reply `TERMINATE` in the end when everything is done.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "def retrieve_content(message, n_results=3):\n",
    "        boss_aid.n_results = n_results  # Set the number of results to be retrieved.\n",
    "        # Check if we need to update the context.\n",
    "        update_context_case1, update_context_case2 = boss_aid._check_update_context(message)\n",
    "        if (update_context_case1 or update_context_case2) and boss_aid.update_context:\n",
    "            boss_aid.problem = message if not hasattr(boss_aid, \"problem\") else boss_aid.problem\n",
    "            _, ret_msg = boss_aid._generate_retrieve_user_reply(message)\n",
    "        else:\n",
    "            ret_msg = boss_aid.generate_init_message(message, n_results=n_results)\n",
    "        return ret_msg if ret_msg else message\n",
    "\n",
    "for agent in [boss, coder, pm, reviewer]:\n",
    "    # register functions for all agents.\n",
    "    agent.register_function(\n",
    "        function_map={\n",
    "            \"retrieve_content\": retrieve_content,\n",
    "        }\n",
    "    )\n",
    "\n",
    "groupchat = autogen.GroupChat(\n",
    "    agents=[boss, coder, pm, reviewer], messages=[], max_round=12\n",
    ")\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)\n",
    "\n",
    "# Start chatting with the boss as this is the user proxy agent.\n",
    "boss.initiate_chat(\n",
    "    manager,\n",
    "    message=\"How to use spark for parallel training in FLAML? Give me sample code.\",\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "PNs-i5AuDT3l",
    "executionInfo": {
     "status": "error",
     "timestamp": 1709398584060,
     "user_tz": 0,
     "elapsed": 441,
     "user": {
      "displayName": "Matthew Zhang",
      "userId": "02723002670783510319"
     }
    },
    "outputId": "f8604990-a651-4b30-d0ab-1b387965943c"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'termination_msg' is not defined",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-8-00e5a8c6c4f7>\u001B[0m in \u001B[0;36m<cell line: 23>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     23\u001B[0m boss = autogen.UserProxyAgent(\n\u001B[1;32m     24\u001B[0m     \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"Boss\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 25\u001B[0;31m     \u001B[0mis_termination_msg\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtermination_msg\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     26\u001B[0m     \u001B[0mhuman_input_mode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"TERMINATE\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m     \u001B[0msystem_message\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"The boss who ask questions and give tasks.\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'termination_msg' is not defined"
     ]
    }
   ]
  }
 ]
}
